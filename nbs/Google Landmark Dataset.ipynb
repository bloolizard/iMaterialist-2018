{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import os.path as path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import pdb\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/landmark-recognition-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = \"/home/edwin/Datasets/competitions/landmark-recognition-challenge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{pwd}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = f\"{pwd}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/edwin/Datasets/competitions/landmark-recognition-challenge/train.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    print(row)\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.array_split(df, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        image_id = index\n",
    "        filepath = f\"{data_dir}/{row['id']}.jpg\"\n",
    "        if path.exists(filepath):\n",
    "            print(\"File already exists\")\n",
    "        else:\n",
    "            ! wget -O \"{filepath}\" \"{row['url']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.map(download_image, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleLandmarkDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = train_ds.df.iloc[idx].id\n",
    "        file = f\"{data_dir}/{image_id}.jpg\"\n",
    "        try:\n",
    "            img = Image.open(file)\n",
    "            img = np.asarray(img)\n",
    "        except Exception as error:\n",
    "            img = np.zeros([1200, 1600, 3])\n",
    "        label = self.df.landmark_id.iloc[idx]\n",
    "        sample = {\n",
    "            \"image\": img,\n",
    "            \"label\": label\n",
    "        }\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (self.output_size, self.output_size), mode='constant')\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": label\n",
    "        }\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        image = torch.from_numpy(image).float()\n",
    "        label = torch.from_numpy(np.array([label]))\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"label\": label\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        self.fc1 = nn.Linear(810 , 4000)\n",
    "        self.fc2 = nn.Linear(4000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 14951)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # original input torch.Size([4, 3, 75, 75])\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "cnn = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple((set(np.sort(df.landmark_id.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ba13c7eb72a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, train_size=1000, test_size=200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_set, train_valid_set = train_test_split(train_set, train_size=100, test_size=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([Rescale(50), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = GoogleLandmarkDataset(df=train_set, transform=composed)\n",
    "test_ds = GoogleLandmarkDataset(df=test_train_set, transform=composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(test_ds, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/edwin/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': \n",
       " (0 ,0 ,.,.) = \n",
       "   0.1340  0.0937  0.1250  ...   0.0926  0.2234  0.3853\n",
       "   0.1604  0.2737  0.2895  ...   0.3483  0.3314  0.3463\n",
       "   0.1049  0.3570  0.3842  ...   0.2586  0.3847  0.3857\n",
       "            ...             ⋱             ...          \n",
       "   0.0516  0.0586  0.0525  ...   0.0198  0.0902  0.1067\n",
       "   0.0331  0.0320  0.0314  ...   0.0174  0.0790  0.0729\n",
       "   0.0264  0.0306  0.0206  ...   0.0284  0.0752  0.0667\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   0.0955  0.0575  0.0552  ...   0.0416  0.1120  0.3542\n",
       "   0.1116  0.1326  0.2175  ...   0.3088  0.2920  0.3173\n",
       "   0.0721  0.2984  0.3626  ...   0.2248  0.3451  0.3523\n",
       "            ...             ⋱             ...          \n",
       "   0.0359  0.0377  0.0321  ...   0.0198  0.0680  0.0800\n",
       "   0.0288  0.0281  0.0220  ...   0.0233  0.0595  0.0533\n",
       "   0.0186  0.0226  0.0128  ...   0.0226  0.0708  0.0471\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "   0.0859  0.0406  0.0450  ...   0.0328  0.0903  0.3200\n",
       "   0.1018  0.0976  0.1671  ...   0.2719  0.2573  0.2955\n",
       "   0.0684  0.2391  0.3479  ...   0.1800  0.3061  0.3188\n",
       "            ...             ⋱             ...          \n",
       "   0.0305  0.0342  0.0275  ...   0.0120  0.0640  0.0619\n",
       "   0.0219  0.0186  0.0244  ...   0.0145  0.0478  0.0405\n",
       "   0.0225  0.0265  0.0167  ...   0.0269  0.0557  0.0353\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.5103  0.5565  0.6070  ...   0.7027  0.6980  0.6991\n",
       "   0.3551  0.3967  0.4005  ...   0.6392  0.6392  0.6300\n",
       "   0.3770  0.3369  0.3955  ...   0.6353  0.6275  0.6242\n",
       "            ...             ⋱             ...          \n",
       "   0.1963  0.1579  0.1577  ...   0.4066  0.3561  0.3938\n",
       "   0.1246  0.0614  0.0692  ...   0.3686  0.4246  0.3930\n",
       "   0.2598  0.0463  0.0744  ...   0.4649  0.3961  0.3935\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       "   0.6504  0.6756  0.7214  ...   0.7615  0.7569  0.7540\n",
       "   0.4380  0.4644  0.4704  ...   0.7294  0.7294  0.7202\n",
       "   0.3772  0.3536  0.4460  ...   0.7255  0.7176  0.7026\n",
       "            ...             ⋱             ...          \n",
       "   0.2367  0.1853  0.1717  ...   0.3517  0.3130  0.3507\n",
       "   0.1521  0.0810  0.0770  ...   0.3255  0.3815  0.3499\n",
       "   0.2833  0.0698  0.0905  ...   0.4217  0.3530  0.3386\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       "   0.8015  0.8189  0.8483  ...   0.8831  0.8784  0.8677\n",
       "   0.5381  0.5530  0.5678  ...   0.8627  0.8627  0.8535\n",
       "   0.3990  0.4493  0.5099  ...   0.8510  0.8431  0.8320\n",
       "            ...             ⋱             ...          \n",
       "   0.3160  0.2595  0.2270  ...   0.3399  0.3052  0.3428\n",
       "   0.2576  0.1555  0.1348  ...   0.3134  0.3658  0.3420\n",
       "   0.3460  0.1326  0.1376  ...   0.4060  0.3373  0.3268\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "   0.1912  0.2005  0.1936  ...   0.2216  0.2260  0.2328\n",
       "   0.1907  0.2005  0.1995  ...   0.2304  0.2157  0.2294\n",
       "   0.2093  0.2034  0.1980  ...   0.2240  0.2240  0.2373\n",
       "            ...             ⋱             ...          \n",
       "   0.1490  0.0368  0.0240  ...   0.0172  0.0025  0.0142\n",
       "   0.2191  0.0255  0.0417  ...   0.0108  0.0206  0.0127\n",
       "   0.1397  0.0343  0.0618  ...   0.0593  0.0412  0.0152\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       "   0.3289  0.3373  0.3466  ...   0.3848  0.3814  0.3716\n",
       "   0.3466  0.3471  0.3515  ...   0.3917  0.3946  0.3863\n",
       "   0.3515  0.3534  0.3637  ...   0.4025  0.3975  0.3956\n",
       "            ...             ⋱             ...          \n",
       "   0.1466  0.0784  0.0735  ...   0.0583  0.0373  0.0407\n",
       "   0.2054  0.0647  0.0794  ...   0.0515  0.0441  0.0539\n",
       "   0.2377  0.0750  0.0902  ...   0.1157  0.0716  0.0632\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       "   0.6270  0.6436  0.6230  ...   0.6480  0.6539  0.6544\n",
       "   0.6245  0.6461  0.6353  ...   0.6529  0.6515  0.6588\n",
       "   0.6402  0.6382  0.6382  ...   0.6583  0.6515  0.6613\n",
       "            ...             ⋱             ...          \n",
       "   0.0926  0.0270  0.0230  ...   0.0348  0.0225  0.0206\n",
       "   0.1500  0.0343  0.0373  ...   0.0397  0.0275  0.0338\n",
       "   0.1598  0.0338  0.0627  ...   0.0358  0.0417  0.0299\n",
       "      ⋮ \n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "   0.5255  0.5324  0.5314  ...   0.9333  0.8824  0.9676\n",
       "   0.5392  0.5412  0.5412  ...   0.7706  0.9382  0.8255\n",
       "   0.5333  0.5431  0.5549  ...   0.7549  0.9402  0.8176\n",
       "            ...             ⋱             ...          \n",
       "   0.2422  0.2951  0.1667  ...   0.3245  0.1637  0.1755\n",
       "   0.1382  0.1157  0.0735  ...   0.1480  0.1147  0.1235\n",
       "   0.1873  0.1265  0.1363  ...   0.0922  0.1990  0.1833\n",
       " \n",
       " (3 ,1 ,.,.) = \n",
       "   0.6814  0.6873  0.6882  ...   0.8676  0.8461  0.9020\n",
       "   0.6843  0.6843  0.6941  ...   0.7422  0.9088  0.7686\n",
       "   0.6843  0.6922  0.7020  ...   0.7000  0.9225  0.7941\n",
       "            ...             ⋱             ...          \n",
       "   0.3471  0.3922  0.2667  ...   0.3735  0.2284  0.2363\n",
       "   0.2382  0.1961  0.1216  ...   0.2176  0.1931  0.2216\n",
       "   0.3069  0.2049  0.2176  ...   0.1412  0.2804  0.2559\n",
       " \n",
       " (3 ,2 ,.,.) = \n",
       "   0.8078  0.8137  0.8157  ...   0.8000  0.8098  0.8422\n",
       "   0.7941  0.8039  0.8118  ...   0.7118  0.8265  0.7255\n",
       "   0.7931  0.8059  0.8118  ...   0.6588  0.8402  0.7294\n",
       "            ...             ⋱             ...          \n",
       "   0.4520  0.4804  0.3549  ...   0.3980  0.3078  0.2951\n",
       "   0.3569  0.2755  0.1471  ...   0.2814  0.2716  0.3392\n",
       "   0.4147  0.2696  0.2686  ...   0.2020  0.3314  0.3480\n",
       " [torch.FloatTensor of size 4x3x50x50], 'label': \n",
       "  13124\n",
       "  12172\n",
       "    878\n",
       "  10902\n",
       " [torch.LongTensor of size 4x1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Variable(sample['image'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = cnn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 11061\n",
       "  6696\n",
       "  9770\n",
       " 13378\n",
       "[torch.LongTensor of size 4x1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  4053\n",
       " 11234\n",
       "  7737\n",
       "  7737\n",
       "[torch.LongTensor of size 4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Epoch:1\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"Epoch:{}\".format(epoch))\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images = Variable(data[\"image\"].cuda())\n",
    "        labels = Variable(data[\"label\"].cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for load_data in testloader:\n",
    "                test_images = Variable(load_data['image'].cuda())\n",
    "                labels = load_data['label']\n",
    "\n",
    "                test_outputs = cnn(test_images)\n",
    "\n",
    "                _, predicted = torch.max(test_outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted.cpu() == labels.view(-1)).sum()\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Correct:{}, Total:{}'.format(correct, total))\n",
    "            print('Iteraton:{}, Loss:{}, Accuracy: {}'.format(iter, loss.data[0], accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraton:32, Loss:8.652276992797852, Accuracy: 6.0\n"
     ]
    }
   ],
   "source": [
    "print('Iteraton:{}, Loss:{}, Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.df.iloc[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
