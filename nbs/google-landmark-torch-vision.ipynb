{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os.path as dpath\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/edwin/Datasets/competitions/landmark-recognition-challenge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f\"{path}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = f\"{path}/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/home/edwin/Datasets/competitions/landmark-recognition-challenge/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        image_id = index\n",
    "        filepath = f\"{test_path}/{row['id']}.jpg\"\n",
    "        if dpath.exists(filepath):\n",
    "            print(\"File already exists\")\n",
    "        else:\n",
    "            ! wget -O \"{filepath}\" \"{row['url']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, row = next(test_labels.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = labels.sample(frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(sample, train_size=0.8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(labels.landmark_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 14951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/edwin/Datasets/competitions/landmark-recognition-challenge/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = '{}.jpg'.format(self.labels['id'].iloc[idx])\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        try:\n",
    "            image = Image.open(fullname).convert('RGB')\n",
    "        except:\n",
    "            img_zeros = np.zeros([224, 224, 3])\n",
    "            image = Image.fromarray(img_zeros.astype('uint8'), 'RGB')\n",
    "        label = self.labels['landmark_id'].iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkTestDataset(Dataset):\n",
    "    def __init__(self, labels, root_dir, transform=None):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = '{}.jpg'.format(self.labels['id'].iloc[idx])\n",
    "        fullname = join(self.root_dir, img_name)\n",
    "        try:\n",
    "            image = Image.open(fullname)\n",
    "        except:\n",
    "            img_zeros = np.zeros([224, 224, 3])\n",
    "            image = Image.fromarray(img_zeros.astype('uint8'), 'RGB')\n",
    "        label = self.labels['landmark_id'].iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                  transforms.CenterCrop(224),\n",
    "                                  transforms.ToTensor()\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LandmarkDataset(train, data_dir, transform=ds_transform)\n",
    "valid_ds = LandmarkDataset(valid, data_dir, transform=ds_transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(axis, inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    axis.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dl))\n",
    "fig = plt.figure(1, figsize=(16, 4))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1,4), axes_pad=0.05)\n",
    "for i in range(img.size()[0]):\n",
    "    ax = grid[i]\n",
    "    imshow(ax, img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 14951])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "if use_gpu:\n",
    "    resnet.cuda()\n",
    "inputs, labels = next(iter(train_dl))\n",
    "if use_gpu:\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "else:\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "outputs = resnet(inputs)\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.585684776306152, Running Loss: 9.585684776306152, Correct: 0, Total: 245, Valid Accuracy: 0.0\n",
      "Loss: 10.00446891784668, Running Loss: 913.9179682731628, Correct: 10, Total: 245, Valid Accuracy: 4.081632653061225\n",
      "Loss: 8.50673770904541, Running Loss: 1723.718605041504, Correct: 16, Total: 245, Valid Accuracy: 6.530612244897959\n",
      "Loss: 8.883787155151367, Running Loss: 8.883787155151367, Correct: 15, Total: 245, Valid Accuracy: 6.122448979591836\n",
      "Loss: 7.571465969085693, Running Loss: 766.7230825424194, Correct: 19, Total: 245, Valid Accuracy: 7.755102040816326\n",
      "Loss: 8.526094436645508, Running Loss: 1500.599160194397, Correct: 21, Total: 245, Valid Accuracy: 8.571428571428571\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        inps, lbls = next(iter(train_dl))\n",
    "        try:\n",
    "            if use_gpu:\n",
    "                resnet = resnet.cuda()\n",
    "                inputs, labels = Variable(inps.cuda()), Variable(lbls.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inps), Variable(lbls)\n",
    "            optimizer.zero_grad()    \n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 100 == 0:\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for data in valid_dl:\n",
    "                    images, labels = data\n",
    "                    outputs = resnet(Variable(images.cuda()))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted.cpu() == labels).sum()\n",
    "                accuracy = 100 * correct / total\n",
    "                print(\"Loss: {}, Running Loss: {}, Correct: {}, Total: {}, Valid Accuracy: {}\".format(\n",
    "                    loss.data[0], running_loss, correct, total, accuracy))\n",
    "        except Exeption as error:\n",
    "            print(inps.size, lbls.size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = resnet(Variable(images.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet, \"resnet_trained.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar Practice.ipynb\t\t\t  imaterialist_full.pkl\r\n",
      "data\t\t\t\t\t  iMaterialist.ipynb\r\n",
      "DataLoader.ipynb\t\t\t  imaterialist.py\r\n",
      "df1.pkl\t\t\t\t\t  pretrained-pytorch-models\r\n",
      "df_full.pkl\t\t\t\t  pretrained-pytorch-models.zip\r\n",
      "Download Script.ipynb\t\t\t  resnet_trained.pkl\r\n",
      "Google Landmark Dataset.ipynb\t\t  Simple Exploration of Data.ipynb\r\n",
      "google-landmark-test-set.ipynb\t\t  Torch Vision Test.ipynb\r\n",
      "google-landmark-torch-vision-Copy1.ipynb  train_df.pkl\r\n",
      "google-landmark-torch-vision.ipynb\t  Train.ipynb\r\n",
      "iDataSample.pkl\t\t\t\t  wget-log\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
